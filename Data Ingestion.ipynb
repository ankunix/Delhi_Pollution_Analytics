{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    " The following publicly available dataset has been downloaded from https://data.gov.in/catalog/historical-daily-ambient-air-quality-data for following years. Note 2010 is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delhi-2005.json\r\n",
      "delhi-2006.json\r\n",
      "delhi-2007.json\r\n",
      "delhi-2008.json\r\n",
      "delhi-2009.json\r\n",
      "delhi-2011.json\r\n",
      "delhi-2012.json\r\n",
      "delhi-2013.json\r\n",
      "delhi-2014.json\r\n",
      "delhi-2015.json\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 delhi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2015=pd.read_json(\"delhi_data/delhi-2015.json\")\n",
    "delhi_2015.columns = delhi_2015.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2015 = delhi_2015[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2014=pd.read_json(\"delhi_data/delhi-2014.json\")\n",
    "delhi_2014.columns = delhi_2014.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2014 = delhi_2014[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2013=pd.read_json(\"delhi_data/delhi-2013.json\")\n",
    "delhi_2013.columns = delhi_2013.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2013 = delhi_2013[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2012=pd.read_json(\"delhi_data/delhi-2012.json\")\n",
    "delhi_2012.columns = delhi_2012.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2012 = delhi_2012[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2011=pd.read_json(\"delhi_data/delhi-2011.json\")\n",
    "delhi_2011.columns = delhi_2011.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2011 = delhi_2011[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ˜’ No Data available on data.gov.in for year 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2009=pd.read_json(\"delhi_data/delhi-2009.json\")\n",
    "delhi_2009.columns = delhi_2009.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2009 = delhi_2009[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2008=pd.read_json(\"delhi_data/delhi-2008.json\")\n",
    "delhi_2008.columns = delhi_2008.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2008 = delhi_2008[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2008=pd.read_json(\"delhi_data/delhi-2008.json\")\n",
    "delhi_2008.columns = delhi_2008.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2008 = delhi_2008[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2007=pd.read_json(\"delhi_data/delhi-2007.json\")\n",
    "delhi_2007.columns = delhi_2007.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2007 = delhi_2007[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2006=pd.read_json(\"delhi_data/delhi-2006.json\")\n",
    "delhi_2006.columns = delhi_2006.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2006 = delhi_2006[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_2005=pd.read_json(\"delhi_data/delhi-2005.json\")\n",
    "delhi_2005.columns = delhi_2005.iloc[0] #set the header row as the dataframe header by grabbing the first row for the header\n",
    "delhi_2005 = delhi_2005[1:] #take the data less the header row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect all the data in a single data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_data=delhi_2005.append(delhi_2006).append(delhi_2007).append(delhi_2006).append(delhi_2007).append(delhi_2008).append(delhi_2009).append(delhi_2011).append(delhi_2012).append(delhi_2013).append(delhi_2014).append(delhi_2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.columns=data.columns.str.strip().str.lower().str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx,row in data.iterrows():\n",
    "    dt=str(row['sampling_date'])\n",
    "    if(dt[-5]=='/'):\n",
    "        ndt=dt.split('/')\n",
    "        dd=\"0\"+ndt[0] if len(ndt[0])<2 else ndt[0]\n",
    "        mm=\"0\"+ndt[1] if len(ndt[1])<2 else ndt[1]\n",
    "        yy=ndt[2][-2:]\n",
    "        data.loc[idx,'sampling_date']=dd+'-'+mm+'-'+yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save all the ingested data to a single csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delhi_data.to_csv(\"delhi_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://m.popkey.co/20f09e/qrVG5.gif\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
